# ğŸ™ï¸ Speech Emotion Recognition from Audio

A deep learning-based system to recognize emotions from speech using the [RAVDESS](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio) dataset. This project extracts audio features (MFCCs) and classifies emotional states using LSTM/CNN architectures.

---

## ğŸ“Œ Overview

This project aims to classify spoken audio clips into the following emotions:

- ğŸ˜ Neutral  
- ğŸ˜Œ Calm  
- ğŸ˜„ Happy  
- ğŸ˜¢ Sad  
- ğŸ˜  Angry  
- ğŸ˜¨ Fearful  
- ğŸ¤¢ Disgust  
- ğŸ˜² Surprised  

It achieves high classification accuracy using MFCC (Mel Frequency Cepstral Coefficients) features and a deep learning model trained on the RAVDESS dataset.

---

## ğŸ§  Model Summary

- **Preprocessing**: MFCC extraction using Librosa
- **Model Architectures**: CNN and LSTM-based deep learning models
- **Accuracy Achieved**: **~88%**
- **Framework**: TensorFlow / Keras

---

## ğŸ—ƒï¸ Dataset

- **Name**: RAVDESS Emotional Speech Audio
- **Size**: 24 professional actors (12 male, 12 female)
- **Classes**: Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised (we selected a subset)
- ğŸ“¥ [Download Dataset from Kaggle](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)

---

## ğŸ› ï¸ Features

- ğŸ§ Audio signal processing with `librosa`
- ğŸ”Š Feature extraction using MFCCs
- ğŸ“Š Training deep neural networks (LSTM / CNN)
- ğŸ“ˆ Visualization of training and evaluation
- ğŸ§ª Early stopping & validation monitoring

---

## ğŸ“Š Results

| Emotion | Precision | Recall | F1-Score |
|---------|-----------|--------|----------|
| Neutral | 0.92      | 0.92   | 0.92     |
| Calm    | 0.85      | 0.86   | 0.85     |
| Happy   | 0.92      | 0.91   | 0.92     |
| Sad     | 0.85      | 0.89   | 0.87     |
| Angry   | 0.82      | 0.80   | 0.81     |

- âœ… Overall Accuracy: **88%**

### ğŸ“ˆ Accuracy & Loss Curves
![Accuracy Plot](images/accuracy_plot.png)

### ğŸ“‰ Confusion Matrix
![Confusion Matrix](images/confusion_matrix.png)

---
